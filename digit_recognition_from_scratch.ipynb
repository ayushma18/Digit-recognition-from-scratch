{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushma18/Digit-recognition-from-scratch/blob/main/digit_recognition_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35066ac4",
      "metadata": {
        "id": "35066ac4"
      },
      "source": [
        "---\n",
        "## ‚ö° QUICK START: Upload and Predict Your Image\n",
        "\n",
        "**Want to test immediately?** Follow these simple steps:\n",
        "\n",
        "1. **Save your handwritten digit image** in this notebook's directory\n",
        "2. **Update the filename** in the cell below\n",
        "3. **Run the cell** to get your prediction!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b18edd35",
      "metadata": {
        "id": "b18edd35"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# üéØ UPLOAD YOUR IMAGE HERE\n",
        "# ================================================================\n",
        "#\n",
        "# INSTRUCTIONS:\n",
        "# 1. Place your handwritten digit image (0-9) in this directory\n",
        "# 2. Update the filename below (e.g., \"my_digit.png\", \"test.jpg\")\n",
        "# 3. Set INVERT_COLORS:\n",
        "#    - True: if your digit is BLACK on WHITE background (most common)\n",
        "#    - False: if your digit is WHITE on BLACK background (like MNIST)\n",
        "# 4. Run this cell!\n",
        "#\n",
        "# NOTE: This cell will work AFTER you complete the training below.\n",
        "# ================================================================\n",
        "\n",
        "# YOUR IMAGE FILENAME HERE:\n",
        "IMAGE_FILENAME = \"my_digit.png\"  # Change this to your image filename\n",
        "\n",
        "# Color setting:\n",
        "INVERT_COLORS = True  # True for black digit on white background\n",
        "\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "# Check if image exists\n",
        "if os.path.exists(IMAGE_FILENAME):\n",
        "    print(\"‚úÖ Image found!\")\n",
        "    print(f\"üìÅ File: {IMAGE_FILENAME}\")\n",
        "    print(\"\\n‚ö†Ô∏è Make sure you have trained the model first by running all cells below.\")\n",
        "    print(\"\\nüìå After training, re-run this cell to see your prediction!\")\n",
        "\n",
        "    # Try to make prediction (will work after training)\n",
        "    try:\n",
        "        from PIL import Image\n",
        "        import numpy as np\n",
        "\n",
        "        # Display the uploaded image\n",
        "        img = Image.open(IMAGE_FILENAME)\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(\"Your Uploaded Image\", fontsize=14, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # Try prediction if model is trained\n",
        "        if 'trained_parameters' in dir():\n",
        "            predicted_digit, confidence, probabilities, _, _ = predict_digit(\n",
        "                IMAGE_FILENAME,\n",
        "                trained_parameters,\n",
        "                invert=INVERT_COLORS\n",
        "            )\n",
        "\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(f\"The uploaded handwritten digit is recognized as: {predicted_digit}\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Confidence: {confidence*100:.2f}%\")\n",
        "            print(\"\\nTop 3 predictions:\")\n",
        "            top_3 = np.argsort(probabilities)[-3:][::-1]\n",
        "            for i, idx in enumerate(top_3, 1):\n",
        "                print(f\"  {i}. Digit {idx}: {probabilities[idx]*100:.2f}%\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "            # Display with visualization\n",
        "            display_prediction(IMAGE_FILENAME, trained_parameters, invert=INVERT_COLORS)\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è Model not trained yet. Please run all cells below to train the model first.\")\n",
        "\n",
        "    except NameError:\n",
        "        print(\"\\n‚ö†Ô∏è Prediction functions not loaded yet.\")\n",
        "        print(\"Please run all cells in this notebook first to:\")\n",
        "        print(\"  1. Define the prediction functions\")\n",
        "        print(\"  2. Train the neural network\")\n",
        "        print(\"  3. Then come back and re-run this cell\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error: {str(e)}\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå Image file '{IMAGE_FILENAME}' not found!\")\n",
        "    print(\"\\nüìã To upload your image:\")\n",
        "    print(\"  1. Save your handwritten digit image (PNG, JPG, JPEG)\")\n",
        "    print(\"  2. Place it in this notebook's directory:\")\n",
        "    print(f\"     {os.getcwd()}\")\n",
        "    print(f\"  3. Update IMAGE_FILENAME variable above\")\n",
        "    print(\"  4. Run this cell again\")\n",
        "    print(\"\\nüí° You can also drag-and-drop the image file into the file browser.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8880edc",
      "metadata": {
        "id": "e8880edc"
      },
      "source": [
        "# Handwritten Digit Recognition from Scratch\n",
        "\n",
        "**Built Without Deep Learning Libraries**\n",
        "\n",
        "This notebook implements a complete neural network from scratch to recognize handwritten digits (0-9) from images.\n",
        "\n",
        "## Key Features:\n",
        "- No TensorFlow, PyTorch, or Keras\n",
        "- Pure algorithmic implementation using NumPy\n",
        "- Detailed mathematical explanations\n",
        "- Custom image input support\n",
        "- Output format: \"The uploaded handwritten digit is recognized as: X\"\n",
        "\n",
        "## Architecture:\n",
        "- Input Layer: 784 neurons (28x28 pixels)\n",
        "- Hidden Layer: 128 neurons (ReLU activation)\n",
        "- Output Layer: 10 neurons (Softmax activation)\n",
        "- Training: Backpropagation with mini-batch gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a781ed2",
      "metadata": {
        "id": "0a781ed2"
      },
      "source": [
        "## 1. Import Required Libraries\n",
        "\n",
        "We'll use only basic libraries:\n",
        "- **NumPy**: For numerical operations and matrix computations\n",
        "- **Matplotlib**: For visualization\n",
        "- **PIL (Pillow)**: For image loading and preprocessing\n",
        "- **urllib**: For downloading MNIST dataset\n",
        "- **gzip**: For decompressing dataset files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "85326729",
      "metadata": {
        "id": "85326729",
        "outputId": "1528c143-5e11-4624-cdfe-aedc82f6a46a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n",
            "NumPy version: 2.0.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import urllib.request\n",
        "import gzip\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d783fb78",
      "metadata": {
        "id": "d783fb78"
      },
      "source": [
        "## 2. Load and Preprocess the MNIST Dataset\n",
        "\n",
        "The MNIST dataset contains 60,000 training images and 10,000 test images of handwritten digits.\n",
        "\n",
        "### Process:\n",
        "1. Download the dataset from the official source\n",
        "2. Extract images and labels\n",
        "3. Normalize pixel values from [0, 255] to [0, 1]\n",
        "4. Flatten 28x28 images into 784-dimensional vectors\n",
        "5. One-hot encode labels for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a9572f22",
      "metadata": {
        "id": "a9572f22",
        "outputId": "fddc27d4-c715-4480-a5b9-73858d7f6d90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LOADING MNIST DATASET\n",
            "============================================================\n",
            "Downloading train-images-idx3-ubyte.gz...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-689188013.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Load training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-689188013.py\u001b[0m in \u001b[0;36mdownload_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading {filename}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloaded {filename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ],
      "source": [
        "def download_mnist():\n",
        "    \"\"\"Download MNIST dataset from the internet\"\"\"\n",
        "    base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
        "    files = {\n",
        "        \"train_images\": \"train-images-idx3-ubyte.gz\",\n",
        "        \"train_labels\": \"train-labels-idx1-ubyte.gz\",\n",
        "        \"test_images\": \"t10k-images-idx3-ubyte.gz\",\n",
        "        \"test_labels\": \"t10k-labels-idx1-ubyte.gz\"\n",
        "    }\n",
        "\n",
        "    data_dir = \"mnist_data\"\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "\n",
        "    for key, filename in files.items():\n",
        "        filepath = os.path.join(data_dir, filename)\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"Downloading {filename}...\")\n",
        "            urllib.request.urlretrieve(base_url + filename, filepath)\n",
        "            print(f\"Downloaded {filename}\")\n",
        "        else:\n",
        "            print(f\"{filename} already exists\")\n",
        "\n",
        "    return data_dir\n",
        "\n",
        "def load_mnist_images(filepath):\n",
        "    \"\"\"Load MNIST images from compressed file\"\"\"\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "        # Read header information\n",
        "        magic = int.from_bytes(f.read(4), 'big')\n",
        "        num_images = int.from_bytes(f.read(4), 'big')\n",
        "        rows = int.from_bytes(f.read(4), 'big')\n",
        "        cols = int.from_bytes(f.read(4), 'big')\n",
        "\n",
        "        # Read image data\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        data = data.reshape(num_images, rows, cols)\n",
        "\n",
        "    return data\n",
        "\n",
        "def load_mnist_labels(filepath):\n",
        "    \"\"\"Load MNIST labels from compressed file\"\"\"\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "        # Read header information\n",
        "        magic = int.from_bytes(f.read(4), 'big')\n",
        "        num_labels = int.from_bytes(f.read(4), 'big')\n",
        "\n",
        "        # Read label data\n",
        "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "\n",
        "    return labels\n",
        "\n",
        "def preprocess_data(images, labels):\n",
        "    \"\"\"\n",
        "    Preprocess images and labels for neural network\n",
        "\n",
        "    Steps:\n",
        "    1. Flatten 28x28 images to 784-dimensional vectors\n",
        "    2. Normalize pixel values from [0, 255] to [0, 1]\n",
        "    3. One-hot encode labels\n",
        "    \"\"\"\n",
        "    # Flatten images: (num_samples, 28, 28) -> (num_samples, 784)\n",
        "    X = images.reshape(images.shape[0], -1)\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    X = X.astype(np.float32) / 255.0\n",
        "\n",
        "    # One-hot encode labels\n",
        "    # Example: label 3 -> [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "    num_classes = 10\n",
        "    Y = np.zeros((labels.shape[0], num_classes))\n",
        "    Y[np.arange(labels.shape[0]), labels] = 1\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# Download and load the dataset\n",
        "print(\"=\" * 60)\n",
        "print(\"LOADING MNIST DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "data_dir = download_mnist()\n",
        "\n",
        "# Load training data\n",
        "train_images = load_mnist_images(os.path.join(data_dir, \"train-images-idx3-ubyte.gz\"))\n",
        "train_labels = load_mnist_labels(os.path.join(data_dir, \"train-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "# Load test data\n",
        "test_images = load_mnist_images(os.path.join(data_dir, \"t10k-images-idx3-ubyte.gz\"))\n",
        "test_labels = load_mnist_labels(os.path.join(data_dir, \"t10k-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "print(f\"\\nRaw Data Shapes:\")\n",
        "print(f\"Training images: {train_images.shape}\")\n",
        "print(f\"Training labels: {train_labels.shape}\")\n",
        "print(f\"Test images: {test_images.shape}\")\n",
        "print(f\"Test labels: {test_labels.shape}\")\n",
        "\n",
        "# Preprocess the data\n",
        "X_train, Y_train = preprocess_data(train_images, train_labels)\n",
        "X_test, Y_test = preprocess_data(test_images, test_labels)\n",
        "\n",
        "print(f\"\\nPreprocessed Data Shapes:\")\n",
        "print(f\"X_train: {X_train.shape} (flattened and normalized)\")\n",
        "print(f\"Y_train: {Y_train.shape} (one-hot encoded)\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"Y_test: {Y_test.shape}\")\n",
        "\n",
        "print(f\"\\nData Statistics:\")\n",
        "print(f\"Pixel value range: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
        "print(f\"Number of classes: {Y_train.shape[1]}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dd9638c",
      "metadata": {
        "id": "9dd9638c"
      },
      "source": [
        "## 3. Visualize Sample Digits\n",
        "\n",
        "Let's visualize some sample handwritten digits from the training dataset to understand what our neural network will be learning from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ac6c2e74",
      "metadata": {
        "id": "ac6c2e74",
        "outputId": "ac2ddc83-a528-433d-fc4b-382fc169dd97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1649370103.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Random index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Display the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 15 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize 15 random samples from the training set\n",
        "num_samples = 15\n",
        "fig, axes = plt.subplots(3, 5, figsize=(12, 7))\n",
        "fig.suptitle('Sample Handwritten Digits from MNIST Dataset', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Random index\n",
        "    idx = np.random.randint(0, len(train_images))\n",
        "\n",
        "    # Display the image\n",
        "    ax.imshow(train_images[idx], cmap='gray')\n",
        "    ax.set_title(f'Label: {train_labels[idx]}', fontsize=12, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Each image is 28x28 pixels representing a handwritten digit (0-9)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c31b3b13",
      "metadata": {
        "id": "c31b3b13"
      },
      "source": [
        "## 4. Initialize Neural Network Parameters\n",
        "\n",
        "### Network Architecture:\n",
        "- **Input Layer**: 784 neurons (28√ó28 pixels)\n",
        "- **Hidden Layer 1**: 128 neurons with ReLU activation\n",
        "- **Output Layer**: 10 neurons (digits 0-9) with Softmax activation\n",
        "\n",
        "### Weight Initialization:\n",
        "We use **He initialization** for ReLU layers:\n",
        "$$W \\sim \\mathcal{N}\\left(0, \\sqrt{\\frac{2}{n_{in}}}\\right)$$\n",
        "\n",
        "Where $n_{in}$ is the number of input neurons to the layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a912290",
      "metadata": {
        "id": "7a912290"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    \"\"\"\n",
        "    Initialize weights and biases for a 2-layer neural network\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    input_size : int\n",
        "        Number of input features (784 for flattened 28x28 images)\n",
        "    hidden_size : int\n",
        "        Number of neurons in the hidden layer\n",
        "    output_size : int\n",
        "        Number of output classes (10 for digits 0-9)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    parameters : dict\n",
        "        Dictionary containing initialized weights and biases\n",
        "    \"\"\"\n",
        "\n",
        "    # He initialization for ReLU activation (hidden layer)\n",
        "    # Multiply by sqrt(2/n) where n is the number of inputs\n",
        "    W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)\n",
        "    b1 = np.zeros((1, hidden_size))\n",
        "\n",
        "    # Xavier initialization for output layer\n",
        "    # Multiply by sqrt(1/n) where n is the number of inputs\n",
        "    W2 = np.random.randn(hidden_size, output_size) * np.sqrt(1.0 / hidden_size)\n",
        "    b2 = np.zeros((1, output_size))\n",
        "\n",
        "    parameters = {\n",
        "        'W1': W1,  # Shape: (784, 128)\n",
        "        'b1': b1,  # Shape: (1, 128)\n",
        "        'W2': W2,  # Shape: (128, 10)\n",
        "        'b2': b2   # Shape: (1, 10)\n",
        "    }\n",
        "\n",
        "    return parameters\n",
        "\n",
        "# Define network architecture\n",
        "INPUT_SIZE = 784   # 28x28 pixels\n",
        "HIDDEN_SIZE = 128  # Hidden layer neurons\n",
        "OUTPUT_SIZE = 10   # 10 classes (digits 0-9)\n",
        "\n",
        "# Initialize parameters\n",
        "parameters = initialize_parameters(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"NEURAL NETWORK PARAMETERS INITIALIZED\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nNetwork Architecture:\")\n",
        "print(f\"  Input Layer:  {INPUT_SIZE} neurons\")\n",
        "print(f\"  Hidden Layer: {HIDDEN_SIZE} neurons (ReLU)\")\n",
        "print(f\"  Output Layer: {OUTPUT_SIZE} neurons (Softmax)\")\n",
        "\n",
        "print(f\"\\nParameter Shapes:\")\n",
        "print(f\"  W1 (Input ‚Üí Hidden):  {parameters['W1'].shape}\")\n",
        "print(f\"  b1 (Hidden bias):     {parameters['b1'].shape}\")\n",
        "print(f\"  W2 (Hidden ‚Üí Output): {parameters['W2'].shape}\")\n",
        "print(f\"  b2 (Output bias):     {parameters['b2'].shape}\")\n",
        "\n",
        "# Calculate total number of parameters\n",
        "total_params = (parameters['W1'].size + parameters['b1'].size +\n",
        "                parameters['W2'].size + parameters['b2'].size)\n",
        "print(f\"\\nTotal trainable parameters: {total_params:,}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cf357a9",
      "metadata": {
        "id": "8cf357a9"
      },
      "source": [
        "## 5. Implement Activation Functions\n",
        "\n",
        "### ReLU (Rectified Linear Unit)\n",
        "$$f(x) = \\max(0, x)$$\n",
        "$$f'(x) = \\begin{cases} 1 & \\text{if } x > 0 \\\\ 0 & \\text{otherwise} \\end{cases}$$\n",
        "\n",
        "### Softmax\n",
        "$$\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}$$\n",
        "\n",
        "Converts raw scores to probability distribution over classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a59a82e5",
      "metadata": {
        "id": "a59a82e5"
      },
      "outputs": [],
      "source": [
        "def relu(Z):\n",
        "    \"\"\"\n",
        "    ReLU activation function: f(x) = max(0, x)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    Z : numpy array\n",
        "        Input to the activation function\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    A : numpy array\n",
        "        Output after applying ReLU\n",
        "    \"\"\"\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "def relu_derivative(Z):\n",
        "    \"\"\"\n",
        "    Derivative of ReLU function\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    Z : numpy array\n",
        "        Input to the activation function\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dZ : numpy array\n",
        "        Gradient of ReLU\n",
        "    \"\"\"\n",
        "    return (Z > 0).astype(float)\n",
        "\n",
        "def softmax(Z):\n",
        "    \"\"\"\n",
        "    Softmax activation function\n",
        "    Converts scores to probability distribution\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    Z : numpy array of shape (batch_size, num_classes)\n",
        "        Raw scores from the output layer\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    A : numpy array of shape (batch_size, num_classes)\n",
        "        Probabilities for each class (sum to 1 across classes)\n",
        "    \"\"\"\n",
        "    # Subtract max for numerical stability (prevents overflow)\n",
        "    exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
        "    return exp_Z / np.sum(exp_Z, axis=1, keepdims=True)\n",
        "\n",
        "# Test activation functions\n",
        "print(\"=\" * 60)\n",
        "print(\"TESTING ACTIVATION FUNCTIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test ReLU\n",
        "test_input = np.array([[-2, -1, 0, 1, 2]])\n",
        "print(\"\\nReLU Test:\")\n",
        "print(f\"  Input:  {test_input[0]}\")\n",
        "print(f\"  Output: {relu(test_input)[0]}\")\n",
        "print(f\"  Derivative: {relu_derivative(test_input)[0]}\")\n",
        "\n",
        "# Test Softmax\n",
        "test_scores = np.array([[2.0, 1.0, 0.1]])\n",
        "softmax_output = softmax(test_scores)\n",
        "print(\"\\nSoftmax Test:\")\n",
        "print(f\"  Input scores: {test_scores[0]}\")\n",
        "print(f\"  Output probabilities: {softmax_output[0]}\")\n",
        "print(f\"  Sum of probabilities: {np.sum(softmax_output):.6f} (should be 1.0)\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f71ee09",
      "metadata": {
        "id": "7f71ee09"
      },
      "source": [
        "## 6. Implement Forward Propagation\n",
        "\n",
        "Forward propagation computes the output of the neural network given an input.\n",
        "\n",
        "### Mathematical Steps:\n",
        "\n",
        "**Layer 1 (Input ‚Üí Hidden):**\n",
        "$$Z_1 = XW_1 + b_1$$\n",
        "$$A_1 = \\text{ReLU}(Z_1) = \\max(0, Z_1)$$\n",
        "\n",
        "**Layer 2 (Hidden ‚Üí Output):**\n",
        "$$Z_2 = A_1W_2 + b_2$$\n",
        "$$A_2 = \\text{Softmax}(Z_2)$$\n",
        "\n",
        "Where:\n",
        "- $X$ is the input (batch of images)\n",
        "- $W_1, b_1$ are weights and biases for hidden layer\n",
        "- $W_2, b_2$ are weights and biases for output layer\n",
        "- $A_1$ is the activation of hidden layer\n",
        "- $A_2$ is the final output (class probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ffb1cb0",
      "metadata": {
        "id": "7ffb1cb0"
      },
      "outputs": [],
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Perform forward propagation through the neural network\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X : numpy array of shape (batch_size, 784)\n",
        "        Input data (flattened images)\n",
        "    parameters : dict\n",
        "        Dictionary containing W1, b1, W2, b2\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    A2 : numpy array of shape (batch_size, 10)\n",
        "        Output layer activations (class probabilities)\n",
        "    cache : dict\n",
        "        Intermediate values needed for backpropagation\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract parameters\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "\n",
        "    # Layer 1: Input ‚Üí Hidden\n",
        "    # Z1 = X @ W1 + b1\n",
        "    Z1 = np.dot(X, W1) + b1        # Shape: (batch_size, 128)\n",
        "    A1 = relu(Z1)                   # Shape: (batch_size, 128)\n",
        "\n",
        "    # Layer 2: Hidden ‚Üí Output\n",
        "    # Z2 = A1 @ W2 + b2\n",
        "    Z2 = np.dot(A1, W2) + b2       # Shape: (batch_size, 10)\n",
        "    A2 = softmax(Z2)                # Shape: (batch_size, 10)\n",
        "\n",
        "    # Store values for backpropagation\n",
        "    cache = {\n",
        "        'X': X,\n",
        "        'Z1': Z1,\n",
        "        'A1': A1,\n",
        "        'Z2': Z2,\n",
        "        'A2': A2\n",
        "    }\n",
        "\n",
        "    return A2, cache\n",
        "\n",
        "# Test forward propagation with a small batch\n",
        "print(\"=\" * 60)\n",
        "print(\"TESTING FORWARD PROPAGATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test with 5 random samples\n",
        "test_batch = X_train[:5]\n",
        "predictions, cache = forward_propagation(test_batch, parameters)\n",
        "\n",
        "print(f\"\\nInput shape: {test_batch.shape}\")\n",
        "print(f\"Output shape: {predictions.shape}\")\n",
        "print(f\"\\nPredictions (probabilities for each class):\")\n",
        "for i in range(5):\n",
        "    predicted_digit = np.argmax(predictions[i])\n",
        "    confidence = predictions[i][predicted_digit]\n",
        "    actual_digit = np.argmax(Y_train[i])\n",
        "    print(f\"  Sample {i+1}: Predicted={predicted_digit} (confidence={confidence:.4f}), Actual={actual_digit}\")\n",
        "\n",
        "print(f\"\\nCache contains: {list(cache.keys())}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc38679d",
      "metadata": {
        "id": "dc38679d"
      },
      "source": [
        "## 7. Implement Loss Function\n",
        "\n",
        "We use **Cross-Entropy Loss** for multi-class classification:\n",
        "\n",
        "$$\\mathcal{L} = -\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{j=1}^{C} y_{ij} \\log(\\hat{y}_{ij})$$\n",
        "\n",
        "Where:\n",
        "- $m$ is the batch size\n",
        "- $C$ is the number of classes (10)\n",
        "- $y_{ij}$ is the true label (one-hot encoded)\n",
        "- $\\hat{y}_{ij}$ is the predicted probability\n",
        "- The loss measures how different predictions are from true labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e21ecd3",
      "metadata": {
        "id": "0e21ecd3"
      },
      "outputs": [],
      "source": [
        "def compute_loss(A2, Y):\n",
        "    \"\"\"\n",
        "    Compute cross-entropy loss\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    A2 : numpy array of shape (batch_size, 10)\n",
        "        Predicted probabilities from output layer\n",
        "    Y : numpy array of shape (batch_size, 10)\n",
        "        True labels (one-hot encoded)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    loss : float\n",
        "        Cross-entropy loss value\n",
        "    \"\"\"\n",
        "    m = Y.shape[0]  # Number of samples\n",
        "\n",
        "    # Add small epsilon to prevent log(0)\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    # Cross-entropy loss: -1/m * sum(y * log(y_hat))\n",
        "    loss = -np.sum(Y * np.log(A2 + epsilon)) / m\n",
        "\n",
        "    return loss\n",
        "\n",
        "def compute_accuracy(A2, Y):\n",
        "    \"\"\"\n",
        "    Compute classification accuracy\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    A2 : numpy array of shape (batch_size, 10)\n",
        "        Predicted probabilities\n",
        "    Y : numpy array of shape (batch_size, 10)\n",
        "        True labels (one-hot encoded)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    accuracy : float\n",
        "        Percentage of correct predictions\n",
        "    \"\"\"\n",
        "    # Get predicted class (highest probability)\n",
        "    predictions = np.argmax(A2, axis=1)\n",
        "\n",
        "    # Get true class\n",
        "    true_labels = np.argmax(Y, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = np.mean(predictions == true_labels) * 100\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Test loss function\n",
        "print(\"=\" * 60)\n",
        "print(\"TESTING LOSS FUNCTION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_predictions, _ = forward_propagation(X_train[:100], parameters)\n",
        "test_labels = Y_train[:100]\n",
        "\n",
        "loss = compute_loss(test_predictions, test_labels)\n",
        "accuracy = compute_accuracy(test_predictions, test_labels)\n",
        "\n",
        "print(f\"\\nTest on 100 samples (untrained network):\")\n",
        "print(f\"  Loss: {loss:.4f}\")\n",
        "print(f\"  Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"  Random guessing would give ~10% accuracy\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77532d33",
      "metadata": {
        "id": "77532d33"
      },
      "source": [
        "## 8. Implement Backpropagation\n",
        "\n",
        "Backpropagation computes gradients of the loss with respect to all parameters using the **chain rule**.\n",
        "\n",
        "### Mathematical Derivation:\n",
        "\n",
        "**Output Layer Gradients:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial Z_2} = A_2 - Y$$\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial W_2} = \\frac{1}{m} A_1^T (A_2 - Y)$$\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial b_2} = \\frac{1}{m} \\sum (A_2 - Y)$$\n",
        "\n",
        "**Hidden Layer Gradients:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial Z_1} = \\frac{\\partial \\mathcal{L}}{\\partial Z_2} \\cdot W_2^T \\odot \\text{ReLU}'(Z_1)$$\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial W_1} = \\frac{1}{m} X^T \\frac{\\partial \\mathcal{L}}{\\partial Z_1}$$\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial b_1} = \\frac{1}{m} \\sum \\frac{\\partial \\mathcal{L}}{\\partial Z_1}$$\n",
        "\n",
        "Where $\\odot$ denotes element-wise multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f894f76",
      "metadata": {
        "id": "1f894f76"
      },
      "outputs": [],
      "source": [
        "def backward_propagation(cache, Y, parameters):\n",
        "    \"\"\"\n",
        "    Perform backward propagation to compute gradients\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    cache : dict\n",
        "        Contains intermediate values from forward propagation\n",
        "    Y : numpy array of shape (batch_size, 10)\n",
        "        True labels (one-hot encoded)\n",
        "    parameters : dict\n",
        "        Current weights and biases\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    gradients : dict\n",
        "        Dictionary containing gradients for all parameters\n",
        "    \"\"\"\n",
        "\n",
        "    m = Y.shape[0]  # Batch size\n",
        "\n",
        "    # Extract values from cache\n",
        "    X = cache['X']\n",
        "    A1 = cache['A1']\n",
        "    A2 = cache['A2']\n",
        "    Z1 = cache['Z1']\n",
        "\n",
        "    # Extract parameters\n",
        "    W2 = parameters['W2']\n",
        "\n",
        "    # ==========================================\n",
        "    # BACKWARD PASS - Layer 2 (Output Layer)\n",
        "    # ==========================================\n",
        "\n",
        "    # Gradient of loss with respect to Z2\n",
        "    # For softmax + cross-entropy: dZ2 = A2 - Y\n",
        "    dZ2 = A2 - Y  # Shape: (batch_size, 10)\n",
        "\n",
        "    # Gradient of loss with respect to W2\n",
        "    # dW2 = (1/m) * A1^T @ dZ2\n",
        "    dW2 = (1/m) * np.dot(A1.T, dZ2)  # Shape: (128, 10)\n",
        "\n",
        "    # Gradient of loss with respect to b2\n",
        "    # db2 = (1/m) * sum(dZ2) across samples\n",
        "    db2 = (1/m) * np.sum(dZ2, axis=0, keepdims=True)  # Shape: (1, 10)\n",
        "\n",
        "    # ==========================================\n",
        "    # BACKWARD PASS - Layer 1 (Hidden Layer)\n",
        "    # ==========================================\n",
        "\n",
        "    # Gradient flowing back from layer 2\n",
        "    # dA1 = dZ2 @ W2^T\n",
        "    dA1 = np.dot(dZ2, W2.T)  # Shape: (batch_size, 128)\n",
        "\n",
        "    # Apply ReLU derivative\n",
        "    # dZ1 = dA1 * ReLU'(Z1)\n",
        "    dZ1 = dA1 * relu_derivative(Z1)  # Shape: (batch_size, 128)\n",
        "\n",
        "    # Gradient of loss with respect to W1\n",
        "    # dW1 = (1/m) * X^T @ dZ1\n",
        "    dW1 = (1/m) * np.dot(X.T, dZ1)  # Shape: (784, 128)\n",
        "\n",
        "    # Gradient of loss with respect to b1\n",
        "    # db1 = (1/m) * sum(dZ1) across samples\n",
        "    db1 = (1/m) * np.sum(dZ1, axis=0, keepdims=True)  # Shape: (1, 128)\n",
        "\n",
        "    # Store all gradients\n",
        "    gradients = {\n",
        "        'dW1': dW1,\n",
        "        'db1': db1,\n",
        "        'dW2': dW2,\n",
        "        'db2': db2\n",
        "    }\n",
        "\n",
        "    return gradients\n",
        "\n",
        "# Test backpropagation\n",
        "print(\"=\" * 60)\n",
        "print(\"TESTING BACKPROPAGATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Forward pass\n",
        "test_batch = X_train[:32]\n",
        "test_labels = Y_train[:32]\n",
        "predictions, cache = forward_propagation(test_batch, parameters)\n",
        "\n",
        "# Backward pass\n",
        "gradients = backward_propagation(cache, test_labels, parameters)\n",
        "\n",
        "print(f\"\\nGradient Shapes:\")\n",
        "print(f\"  dW1: {gradients['dW1'].shape} (should match W1: {parameters['W1'].shape})\")\n",
        "print(f\"  db1: {gradients['db1'].shape} (should match b1: {parameters['b1'].shape})\")\n",
        "print(f\"  dW2: {gradients['dW2'].shape} (should match W2: {parameters['W2'].shape})\")\n",
        "print(f\"  db2: {gradients['db2'].shape} (should match b2: {parameters['b2'].shape})\")\n",
        "\n",
        "print(f\"\\nSample Gradient Statistics:\")\n",
        "print(f\"  dW1 - mean: {np.mean(gradients['dW1']):.6f}, std: {np.std(gradients['dW1']):.6f}\")\n",
        "print(f\"  dW2 - mean: {np.mean(gradients['dW2']):.6f}, std: {np.std(gradients['dW2']):.6f}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc323fe6",
      "metadata": {
        "id": "bc323fe6"
      },
      "source": [
        "## 9. Implement Gradient Descent\n",
        "\n",
        "Gradient descent updates parameters in the direction that reduces the loss:\n",
        "\n",
        "$$W := W - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial W}$$\n",
        "$$b := b - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial b}$$\n",
        "\n",
        "Where $\\alpha$ is the **learning rate** that controls the step size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59dd4a6b",
      "metadata": {
        "id": "59dd4a6b"
      },
      "outputs": [],
      "source": [
        "def update_parameters(parameters, gradients, learning_rate):\n",
        "    \"\"\"\n",
        "    Update parameters using gradient descent\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    parameters : dict\n",
        "        Current weights and biases\n",
        "    gradients : dict\n",
        "        Gradients computed from backpropagation\n",
        "    learning_rate : float\n",
        "        Step size for parameter updates\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    parameters : dict\n",
        "        Updated weights and biases\n",
        "    \"\"\"\n",
        "\n",
        "    # Update weights and biases for layer 1\n",
        "    parameters['W1'] = parameters['W1'] - learning_rate * gradients['dW1']\n",
        "    parameters['b1'] = parameters['b1'] - learning_rate * gradients['db1']\n",
        "\n",
        "    # Update weights and biases for layer 2\n",
        "    parameters['W2'] = parameters['W2'] - learning_rate * gradients['dW2']\n",
        "    parameters['b2'] = parameters['b2'] - learning_rate * gradients['db2']\n",
        "\n",
        "    return parameters\n",
        "\n",
        "# Test parameter update\n",
        "print(\"=\" * 60)\n",
        "print(\"TESTING PARAMETER UPDATE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Store original parameter values\n",
        "original_W1 = parameters['W1'].copy()\n",
        "\n",
        "# Perform one update\n",
        "learning_rate = 0.01\n",
        "parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "\n",
        "# Check if parameters changed\n",
        "param_change = np.mean(np.abs(parameters['W1'] - original_W1))\n",
        "print(f\"\\nLearning rate: {learning_rate}\")\n",
        "print(f\"Average change in W1: {param_change:.8f}\")\n",
        "print(\"Parameters updated successfully!\")\n",
        "\n",
        "# Re-initialize for training\n",
        "parameters = initialize_parameters(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
        "print(\"\\nParameters re-initialized for training\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2727e329",
      "metadata": {
        "id": "2727e329"
      },
      "source": [
        "## 10. Train the Neural Network\n",
        "\n",
        "Now we combine all components to train the neural network using **mini-batch gradient descent**.\n",
        "\n",
        "### Training Process:\n",
        "1. Split training data into mini-batches\n",
        "2. For each epoch:\n",
        "   - Shuffle the data\n",
        "   - For each mini-batch:\n",
        "     - Forward propagation\n",
        "     - Compute loss\n",
        "     - Backward propagation\n",
        "     - Update parameters\n",
        "   - Track loss and accuracy\n",
        "\n",
        "### Hyperparameters:\n",
        "- **Epochs**: 10 (number of complete passes through training data)\n",
        "- **Batch size**: 128 (number of samples per mini-batch)\n",
        "- **Learning rate**: 0.1 (step size for gradient descent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2443cd5f",
      "metadata": {
        "id": "2443cd5f"
      },
      "outputs": [],
      "source": [
        "def train_neural_network(X_train, Y_train, X_val, Y_val, epochs=10, batch_size=128, learning_rate=0.1):\n",
        "    \"\"\"\n",
        "    Train the neural network using mini-batch gradient descent\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X_train : numpy array\n",
        "        Training data\n",
        "    Y_train : numpy array\n",
        "        Training labels (one-hot encoded)\n",
        "    X_val : numpy array\n",
        "        Validation data\n",
        "    Y_val : numpy array\n",
        "        Validation labels (one-hot encoded)\n",
        "    epochs : int\n",
        "        Number of complete passes through training data\n",
        "    batch_size : int\n",
        "        Number of samples per mini-batch\n",
        "    learning_rate : float\n",
        "        Step size for gradient descent\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    parameters : dict\n",
        "        Trained weights and biases\n",
        "    history : dict\n",
        "        Training history (loss and accuracy over epochs)\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize parameters\n",
        "    parameters = initialize_parameters(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "\n",
        "    num_samples = X_train.shape[0]\n",
        "    num_batches = num_samples // batch_size\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"TRAINING NEURAL NETWORK\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Training samples: {num_samples}\")\n",
        "    print(f\"Validation samples: {X_val.shape[0]}\")\n",
        "    print(f\"Epochs: {epochs}\")\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    print(f\"Batches per epoch: {num_batches}\")\n",
        "    print(f\"Learning rate: {learning_rate}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        # Shuffle training data\n",
        "        indices = np.random.permutation(num_samples)\n",
        "        X_shuffled = X_train[indices]\n",
        "        Y_shuffled = Y_train[indices]\n",
        "\n",
        "        epoch_loss = 0\n",
        "        epoch_correct = 0\n",
        "\n",
        "        # Mini-batch training\n",
        "        for batch in range(num_batches):\n",
        "            # Get mini-batch\n",
        "            start_idx = batch * batch_size\n",
        "            end_idx = start_idx + batch_size\n",
        "            X_batch = X_shuffled[start_idx:end_idx]\n",
        "            Y_batch = Y_shuffled[start_idx:end_idx]\n",
        "\n",
        "            # Forward propagation\n",
        "            A2, cache = forward_propagation(X_batch, parameters)\n",
        "\n",
        "            # Compute loss\n",
        "            batch_loss = compute_loss(A2, Y_batch)\n",
        "            epoch_loss += batch_loss\n",
        "\n",
        "            # Count correct predictions\n",
        "            predictions = np.argmax(A2, axis=1)\n",
        "            true_labels = np.argmax(Y_batch, axis=1)\n",
        "            epoch_correct += np.sum(predictions == true_labels)\n",
        "\n",
        "            # Backward propagation\n",
        "            gradients = backward_propagation(cache, Y_batch, parameters)\n",
        "\n",
        "            # Update parameters\n",
        "            parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        train_loss = epoch_loss / num_batches\n",
        "        train_acc = (epoch_correct / num_samples) * 100\n",
        "\n",
        "        # Validation\n",
        "        val_predictions, _ = forward_propagation(X_val, parameters)\n",
        "        val_loss = compute_loss(val_predictions, Y_val)\n",
        "        val_acc = compute_accuracy(val_predictions, Y_val)\n",
        "\n",
        "        # Store history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    return parameters, history\n",
        "\n",
        "# Split training data into train and validation sets\n",
        "split_idx = 50000\n",
        "X_train_split = X_train[:split_idx]\n",
        "Y_train_split = Y_train[:split_idx]\n",
        "X_val = X_train[split_idx:]\n",
        "Y_val = Y_train[split_idx:]\n",
        "\n",
        "print(f\"Training set: {X_train_split.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
        "print()\n",
        "\n",
        "# Train the network\n",
        "trained_parameters, training_history = train_neural_network(\n",
        "    X_train_split,\n",
        "    Y_train_split,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    learning_rate=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b20c4960",
      "metadata": {
        "id": "b20c4960"
      },
      "source": [
        "### Visualize Training Progress\n",
        "\n",
        "Let's plot the training and validation loss/accuracy over epochs to see how well the model learned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a94e08",
      "metadata": {
        "id": "52a94e08"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot loss\n",
        "epochs_range = range(1, len(training_history['train_loss']) + 1)\n",
        "ax1.plot(epochs_range, training_history['train_loss'], 'b-o', label='Training Loss', linewidth=2)\n",
        "ax1.plot(epochs_range, training_history['val_loss'], 'r-s', label='Validation Loss', linewidth=2)\n",
        "ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Loss over Epochs', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot accuracy\n",
        "ax2.plot(epochs_range, training_history['train_acc'], 'b-o', label='Training Accuracy', linewidth=2)\n",
        "ax2.plot(epochs_range, training_history['val_acc'], 'r-s', label='Validation Accuracy', linewidth=2)\n",
        "ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Accuracy over Epochs', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final Training Accuracy: {training_history['train_acc'][-1]:.2f}%\")\n",
        "print(f\"Final Validation Accuracy: {training_history['val_acc'][-1]:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb248924",
      "metadata": {
        "id": "bb248924"
      },
      "source": [
        "## 11. Evaluate Model Accuracy\n",
        "\n",
        "Let's evaluate the trained model on the test dataset to see how well it generalizes to unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c33e6d",
      "metadata": {
        "id": "04c33e6d"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"=\" * 60)\n",
        "print(\"EVALUATING MODEL ON TEST SET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Make predictions on test set\n",
        "test_predictions, _ = forward_propagation(X_test, trained_parameters)\n",
        "test_loss = compute_loss(test_predictions, Y_test)\n",
        "test_acc = compute_accuracy(test_predictions, Y_test)\n",
        "\n",
        "print(f\"\\nTest Set Performance:\")\n",
        "print(f\"  Loss: {test_loss:.4f}\")\n",
        "print(f\"  Accuracy: {test_acc:.2f}%\")\n",
        "print(f\"  Correct predictions: {int(test_acc * len(X_test) / 100)} / {len(X_test)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Show some correct and incorrect predictions\n",
        "predicted_labels = np.argmax(test_predictions, axis=1)\n",
        "true_labels = np.argmax(Y_test, axis=1)\n",
        "correct_mask = (predicted_labels == true_labels)\n",
        "incorrect_mask = ~correct_mask\n",
        "\n",
        "# Visualize correct predictions\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "fig.suptitle('Correct Predictions', fontsize=16, fontweight='bold')\n",
        "\n",
        "correct_indices = np.where(correct_mask)[0][:10]\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    idx = correct_indices[i]\n",
        "    ax.imshow(test_images[idx], cmap='gray')\n",
        "    confidence = test_predictions[idx][predicted_labels[idx]]\n",
        "    ax.set_title(f'Predicted: {predicted_labels[idx]}\\nTrue: {true_labels[idx]}\\nConf: {confidence:.2f}',\n",
        "                 fontsize=10)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize incorrect predictions\n",
        "if np.sum(incorrect_mask) > 0:\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "    fig.suptitle('Incorrect Predictions (if any)', fontsize=16, fontweight='bold', color='red')\n",
        "\n",
        "    incorrect_indices = np.where(incorrect_mask)[0][:10]\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(incorrect_indices):\n",
        "            idx = incorrect_indices[i]\n",
        "            ax.imshow(test_images[idx], cmap='gray')\n",
        "            confidence = test_predictions[idx][predicted_labels[idx]]\n",
        "            ax.set_title(f'Predicted: {predicted_labels[idx]}\\nTrue: {true_labels[idx]}\\nConf: {confidence:.2f}',\n",
        "                         fontsize=10, color='red')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb0a146",
      "metadata": {
        "id": "ceb0a146"
      },
      "source": [
        "## 12. Load and Preprocess Custom Image\n",
        "\n",
        "This section implements the image input system to accept handwritten digit images and prepare them for prediction.\n",
        "\n",
        "### Image Preprocessing Steps:\n",
        "1. Load the image file (PNG, JPG, JPEG supported)\n",
        "2. Convert to grayscale\n",
        "3. Resize to 28√ó28 pixels\n",
        "4. Invert colors (if needed - MNIST digits are white on black background)\n",
        "5. Normalize pixel values to [0, 1]\n",
        "6. Flatten to 784-dimensional vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe408b59",
      "metadata": {
        "id": "fe408b59"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(image_path, invert=True):\n",
        "    \"\"\"\n",
        "    Load and preprocess a custom handwritten digit image\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    image_path : str\n",
        "        Path to the image file\n",
        "    invert : bool\n",
        "        If True, invert colors (for images with black digits on white background)\n",
        "        MNIST expects white digits on black background\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    image_array : numpy array of shape (1, 784)\n",
        "        Preprocessed image ready for prediction\n",
        "    original_image : PIL Image\n",
        "        Original loaded image for visualization\n",
        "    processed_image : numpy array of shape (28, 28)\n",
        "        Processed image for visualization\n",
        "    \"\"\"\n",
        "\n",
        "    # Load image\n",
        "    img = Image.open(image_path)\n",
        "    original_image = img.copy()\n",
        "\n",
        "    # Convert to grayscale\n",
        "    img = img.convert('L')\n",
        "\n",
        "    # Resize to 28x28 pixels\n",
        "    img = img.resize((28, 28), Image.Resampling.LANCZOS)\n",
        "\n",
        "    # Convert to numpy array\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # Invert colors if needed (MNIST has white digits on black background)\n",
        "    if invert:\n",
        "        img_array = 255 - img_array\n",
        "\n",
        "    # Store for visualization\n",
        "    processed_image = img_array.copy()\n",
        "\n",
        "    # Normalize to [0, 1]\n",
        "    img_array = img_array.astype(np.float32) / 255.0\n",
        "\n",
        "    # Flatten to 784-dimensional vector\n",
        "    img_array = img_array.reshape(1, 784)\n",
        "\n",
        "    return img_array, original_image, processed_image\n",
        "\n",
        "# Save a sample image from test set to demonstrate\n",
        "sample_idx = 42\n",
        "sample_image = test_images[sample_idx]\n",
        "sample_pil = Image.fromarray(sample_image)\n",
        "sample_path = \"sample_digit.png\"\n",
        "sample_pil.save(sample_path)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CUSTOM IMAGE PREPROCESSING\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nSaved sample image: {sample_path}\")\n",
        "print(f\"Actual label: {test_labels[sample_idx]}\")\n",
        "print(\"\\nImage preprocessing function ready!\")\n",
        "print(\"\\nTo use with your own image:\")\n",
        "print(\"  1. Save your handwritten digit image\")\n",
        "print(\"  2. Call: load_and_preprocess_image('your_image.png')\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc0ab226",
      "metadata": {
        "id": "cc0ab226"
      },
      "source": [
        "## 13. Make Prediction on Custom Image\n",
        "\n",
        "This section implements the prediction system that:\n",
        "1. Accepts a preprocessed image\n",
        "2. Runs forward propagation through the trained neural network\n",
        "3. Extracts the predicted digit\n",
        "4. Outputs the result in the specified format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "896af836",
      "metadata": {
        "id": "896af836"
      },
      "outputs": [],
      "source": [
        "def predict_digit(image_path, parameters, invert=True):\n",
        "    \"\"\"\n",
        "    Predict the digit in a custom image\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    image_path : str\n",
        "        Path to the image file\n",
        "    parameters : dict\n",
        "        Trained neural network parameters\n",
        "    invert : bool\n",
        "        Whether to invert colors\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    predicted_digit : int\n",
        "        The predicted digit (0-9)\n",
        "    confidence : float\n",
        "        Confidence score for the prediction\n",
        "    probabilities : numpy array\n",
        "        Probability distribution over all classes\n",
        "    \"\"\"\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    image_array, original_image, processed_image = load_and_preprocess_image(image_path, invert)\n",
        "\n",
        "    # Forward propagation to get predictions\n",
        "    predictions, _ = forward_propagation(image_array, parameters)\n",
        "\n",
        "    # Extract predicted digit (class with highest probability)\n",
        "    predicted_digit = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_digit]\n",
        "    probabilities = predictions[0]\n",
        "\n",
        "    return predicted_digit, confidence, probabilities, original_image, processed_image\n",
        "\n",
        "# Test with a sample image\n",
        "print(\"=\" * 70)\n",
        "print(\"TESTING PREDICTION ON CUSTOM IMAGE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Predict on the sample image we saved\n",
        "predicted_digit, confidence, probabilities, orig_img, proc_img = predict_digit(\n",
        "    \"sample_digit.png\",\n",
        "    trained_parameters,\n",
        "    invert=False  # MNIST images are already white on black\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"The uploaded handwritten digit is recognized as: {predicted_digit}\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\nConfidence: {confidence:.4f} ({confidence*100:.2f}%)\")\n",
        "print(f\"\\nProbability distribution across all digits:\")\n",
        "for digit in range(10):\n",
        "    bar = '‚ñà' * int(probabilities[digit] * 50)\n",
        "    print(f\"  Digit {digit}: {probabilities[digit]:.4f} {bar}\")\n",
        "\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2587fc8f",
      "metadata": {
        "id": "2587fc8f"
      },
      "source": [
        "## 14. Display Prediction Result\n",
        "\n",
        "Visualize the uploaded image alongside the prediction result with confidence scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33f22380",
      "metadata": {
        "id": "33f22380"
      },
      "outputs": [],
      "source": [
        "def display_prediction(image_path, parameters, invert=True):\n",
        "    \"\"\"\n",
        "    Display the image and prediction result in a nice visualization\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    image_path : str\n",
        "        Path to the image file\n",
        "    parameters : dict\n",
        "        Trained neural network parameters\n",
        "    invert : bool\n",
        "        Whether to invert colors\n",
        "    \"\"\"\n",
        "\n",
        "    # Get prediction\n",
        "    predicted_digit, confidence, probabilities, orig_img, proc_img = predict_digit(\n",
        "        image_path, parameters, invert\n",
        "    )\n",
        "\n",
        "    # Create visualization\n",
        "    fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Original image\n",
        "    ax1 = plt.subplot(1, 3, 1)\n",
        "    ax1.imshow(orig_img, cmap='gray')\n",
        "    ax1.set_title('Original Image', fontsize=14, fontweight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Processed image (28x28)\n",
        "    ax2 = plt.subplot(1, 3, 2)\n",
        "    ax2.imshow(proc_img, cmap='gray')\n",
        "    ax2.set_title('Processed Image (28√ó28)', fontsize=14, fontweight='bold')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # Probability bar chart\n",
        "    ax3 = plt.subplot(1, 3, 3)\n",
        "    digits = np.arange(10)\n",
        "    colors = ['green' if i == predicted_digit else 'blue' for i in digits]\n",
        "    bars = ax3.bar(digits, probabilities, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "    bars[predicted_digit].set_color('red')\n",
        "    bars[predicted_digit].set_alpha(1.0)\n",
        "    ax3.set_xlabel('Digit', fontsize=12, fontweight='bold')\n",
        "    ax3.set_ylabel('Probability', fontsize=12, fontweight='bold')\n",
        "    ax3.set_title('Class Probabilities', fontsize=14, fontweight='bold')\n",
        "    ax3.set_xticks(digits)\n",
        "    ax3.set_ylim([0, 1])\n",
        "    ax3.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the required output format\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"The uploaded handwritten digit is recognized as: {predicted_digit}\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Confidence: {confidence*100:.2f}%\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "# Display the prediction for our sample image\n",
        "display_prediction(\"sample_digit.png\", trained_parameters, invert=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abb6ad82",
      "metadata": {
        "id": "abb6ad82"
      },
      "source": [
        "### Test with Multiple Images\n",
        "\n",
        "Let's test the system with multiple test images to demonstrate its capability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08239f23",
      "metadata": {
        "id": "08239f23"
      },
      "outputs": [],
      "source": [
        "# Create and test multiple sample images\n",
        "sample_indices = [7, 42, 123, 456, 789, 1111]\n",
        "sample_images_paths = []\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CREATING SAMPLE TEST IMAGES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for idx in sample_indices:\n",
        "    img = test_images[idx]\n",
        "    label = test_labels[idx]\n",
        "    path = f\"test_digit_{label}_sample_{idx}.png\"\n",
        "    Image.fromarray(img).save(path)\n",
        "    sample_images_paths.append(path)\n",
        "    print(f\"Created: {path} (actual label: {label})\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nTESTING PREDICTIONS ON MULTIPLE IMAGES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test each image\n",
        "for img_path in sample_images_paths:\n",
        "    predicted_digit, confidence, _, _, _ = predict_digit(img_path, trained_parameters, invert=False)\n",
        "    print(f\"\\nFile: {img_path}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"The uploaded handwritten digit is recognized as: {predicted_digit}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Confidence: {confidence*100:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ALL PREDICTIONS COMPLETED\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8720ec42",
      "metadata": {
        "id": "8720ec42"
      },
      "source": [
        "### Save the Trained Model\n",
        "\n",
        "Save the trained neural network parameters for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3be457",
      "metadata": {
        "id": "2c3be457"
      },
      "outputs": [],
      "source": [
        "# Save the trained parameters\n",
        "model_path = \"trained_digit_recognizer.pkl\"\n",
        "\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(trained_parameters, f)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"MODEL SAVED\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nModel saved to: {model_path}\")\n",
        "print(\"\\nTo load the model later:\")\n",
        "print(\"```python\")\n",
        "print(\"with open('trained_digit_recognizer.pkl', 'rb') as f:\")\n",
        "print(\"    loaded_parameters = pickle.load(f)\")\n",
        "print(\"```\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Demonstrate loading\n",
        "with open(model_path, 'rb') as f:\n",
        "    loaded_parameters = pickle.load(f)\n",
        "\n",
        "print(\"\\nModel loaded successfully!\")\n",
        "print(\"Verifying loaded model with a test prediction...\")\n",
        "\n",
        "# Test loaded model\n",
        "test_pred, test_conf, _, _, _ = predict_digit(sample_images_paths[0], loaded_parameters, invert=False)\n",
        "print(f\"Test prediction: {test_pred} (confidence: {test_conf*100:.2f}%)\")\n",
        "print(\"Loaded model works correctly!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37de2784",
      "metadata": {
        "id": "37de2784"
      },
      "source": [
        "---\n",
        "\n",
        "## üìù How to Use This System with Your Own Images\n",
        "\n",
        "### Step 1: Prepare Your Image\n",
        "- Draw or scan a handwritten digit (0-9)\n",
        "- Save it as PNG, JPG, or JPEG format\n",
        "- The digit should be clearly visible\n",
        "\n",
        "### Step 2: Load and Predict\n",
        "```python\n",
        "# For images with BLACK digit on WHITE background (most common):\n",
        "display_prediction(\"your_image.png\", trained_parameters, invert=True)\n",
        "\n",
        "# For images with WHITE digit on BLACK background (like MNIST):\n",
        "display_prediction(\"your_image.png\", trained_parameters, invert=False)\n",
        "```\n",
        "\n",
        "### Step 3: View Results\n",
        "The system will display:\n",
        "- Original image\n",
        "- Preprocessed 28√ó28 image\n",
        "- Probability distribution for all digits\n",
        "- **Output message**: \"The uploaded handwritten digit is recognized as: X\"\n",
        "\n",
        "---\n",
        "\n",
        "## üîç System Components Summary\n",
        "\n",
        "### ‚úÖ What We Implemented (From Scratch):\n",
        "\n",
        "1. **Neural Network Architecture**\n",
        "   - Input Layer: 784 neurons\n",
        "   - Hidden Layer: 128 neurons with ReLU activation\n",
        "   - Output Layer: 10 neurons with Softmax activation\n",
        "\n",
        "2. **Forward Propagation**\n",
        "   - Linear transformations (matrix multiplication)\n",
        "   - Activation functions (ReLU, Softmax)\n",
        "\n",
        "3. **Loss Function**\n",
        "   - Cross-entropy loss for multi-class classification\n",
        "\n",
        "4. **Backpropagation**\n",
        "   - Gradient computation using chain rule\n",
        "   - Layer-by-layer gradient flow\n",
        "\n",
        "5. **Optimization**\n",
        "   - Mini-batch gradient descent\n",
        "   - Parameter updates with learning rate\n",
        "\n",
        "6. **Image Processing**\n",
        "   - Load, resize, normalize images\n",
        "   - Convert to neural network input format\n",
        "\n",
        "7. **Prediction System**\n",
        "   - Forward pass on custom images\n",
        "   - Output in specified format\n",
        "\n",
        "### üìä Performance Achieved:\n",
        "- Test Accuracy: ~95-97% (typical for this architecture)\n",
        "- Training Time: ~10 epochs\n",
        "- No TensorFlow, PyTorch, or Keras used!\n",
        "\n",
        "### üöÄ Libraries Used (Only Basic Tools):\n",
        "- **NumPy**: Matrix operations and numerical computations\n",
        "- **Matplotlib**: Visualization\n",
        "- **PIL (Pillow)**: Image loading and preprocessing\n",
        "- **pickle**: Model saving/loading\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8349882",
      "metadata": {
        "id": "b8349882"
      },
      "source": [
        "## üéØ Quick Start Example\n",
        "\n",
        "Use this cell to quickly test with your own image!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5359862d",
      "metadata": {
        "id": "5359862d"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# CUSTOMIZE THIS SECTION FOR YOUR IMAGE\n",
        "# ========================================\n",
        "\n",
        "# Replace this with the path to your image\n",
        "YOUR_IMAGE_PATH = \"sample_digit.png\"\n",
        "\n",
        "# Set to True if your image has BLACK digit on WHITE background\n",
        "# Set to False if your image has WHITE digit on BLACK background\n",
        "INVERT_COLORS = False\n",
        "\n",
        "# ========================================\n",
        "# RUN PREDICTION\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"üîç ANALYZING YOUR HANDWRITTEN DIGIT...\" + \"\\n\")\n",
        "\n",
        "try:\n",
        "    # Make prediction\n",
        "    predicted_digit, confidence, probabilities, orig_img, proc_img = predict_digit(\n",
        "        YOUR_IMAGE_PATH,\n",
        "        trained_parameters,\n",
        "        invert=INVERT_COLORS\n",
        "    )\n",
        "\n",
        "    # Display visualization\n",
        "    display_prediction(YOUR_IMAGE_PATH, trained_parameters, invert=INVERT_COLORS)\n",
        "\n",
        "    # Print detailed results\n",
        "    print(f\"\\n‚úÖ PREDICTION SUCCESSFUL!\")\n",
        "    print(f\"\\nTop 3 predictions:\")\n",
        "    top_3_indices = np.argsort(probabilities)[-3:][::-1]\n",
        "    for i, idx in enumerate(top_3_indices, 1):\n",
        "        print(f\"  {i}. Digit {idx}: {probabilities[idx]*100:.2f}%\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: Image file '{YOUR_IMAGE_PATH}' not found!\")\n",
        "    print(\"\\nPlease:\")\n",
        "    print(\"  1. Save your handwritten digit image in the same directory\")\n",
        "    print(\"  2. Update YOUR_IMAGE_PATH variable above\")\n",
        "    print(\"  3. Run this cell again\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error occurred: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36d57fc5",
      "metadata": {
        "id": "36d57fc5"
      },
      "source": [
        "---\n",
        "\n",
        "## üìê Mathematical Concepts Implemented\n",
        "\n",
        "### 1. Forward Propagation\n",
        "$$Z_1 = XW_1 + b_1$$\n",
        "$$A_1 = \\text{ReLU}(Z_1) = \\max(0, Z_1)$$\n",
        "$$Z_2 = A_1W_2 + b_2$$\n",
        "$$A_2 = \\text{Softmax}(Z_2) = \\frac{e^{Z_2}}{\\sum e^{Z_2}}$$\n",
        "\n",
        "### 2. Cross-Entropy Loss\n",
        "$$\\mathcal{L} = -\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{j=1}^{10} y_{ij} \\log(\\hat{y}_{ij})$$\n",
        "\n",
        "### 3. Backpropagation Gradients\n",
        "**Output Layer:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial Z_2} = A_2 - Y$$\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial W_2} = \\frac{1}{m} A_1^T (A_2 - Y)$$\n",
        "\n",
        "**Hidden Layer:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial Z_1} = \\frac{\\partial \\mathcal{L}}{\\partial Z_2} W_2^T \\odot \\text{ReLU}'(Z_1)$$\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial W_1} = \\frac{1}{m} X^T \\frac{\\partial \\mathcal{L}}{\\partial Z_1}$$\n",
        "\n",
        "### 4. Gradient Descent Update\n",
        "$$W := W - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial W}$$\n",
        "$$b := b - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial b}$$\n",
        "\n",
        "Where $\\alpha$ is the learning rate.\n",
        "\n",
        "---\n",
        "\n",
        "## üéì Congratulations!\n",
        "\n",
        "You have successfully implemented a complete neural network from scratch without using any deep learning libraries! This notebook demonstrates:\n",
        "\n",
        "‚úÖ **Neural Network Fundamentals**: Forward/backward propagation, activation functions  \n",
        "‚úÖ **Optimization**: Gradient descent, mini-batch training  \n",
        "‚úÖ **Image Processing**: Loading, preprocessing, normalization  \n",
        "‚úÖ **Prediction System**: Custom image input with specified output format  \n",
        "‚úÖ **High Accuracy**: ~95-97% on MNIST test set  \n",
        "\n",
        "**Next Steps:**\n",
        "- Try with your own handwritten digits\n",
        "- Experiment with different architectures (more layers, different sizes)\n",
        "- Implement additional features (momentum, learning rate decay)\n",
        "- Try on other datasets\n",
        "\n",
        "---\n",
        "\n",
        "**End of Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac2b9797",
      "metadata": {
        "id": "ac2b9797"
      },
      "source": [
        "---\n",
        "\n",
        "# üéØ Test Your Own Image Now!\n",
        "\n",
        "Now that your model is trained, use this section to test it with your own handwritten digit images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02b0558d",
      "metadata": {
        "id": "02b0558d"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üì§ UPLOAD AND TEST YOUR IMAGE HERE\n",
        "# ============================================================\n",
        "#\n",
        "# STEP 1: Save your handwritten digit image in this folder\n",
        "# STEP 2: Change the filename below to match your image\n",
        "# STEP 3: Run this cell to get the prediction!\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "# üëâ CHANGE THIS TO YOUR IMAGE FILENAME:\n",
        "my_image = \"my_digit.png\"  # e.g., \"my_digit.png\", \"test.jpg\", \"handwritten_5.png\"\n",
        "\n",
        "# üëâ SET COLOR INVERSION:\n",
        "# - True: if you have BLACK digit on WHITE background (most common)\n",
        "# - False: if you have WHITE digit on BLACK background (like MNIST)\n",
        "invert = True\n",
        "\n",
        "# ============================================================\n",
        "# Prediction Code (Don't modify below unless you know what you're doing)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "if not os.path.exists(my_image):\n",
        "    print(\"=\" * 70)\n",
        "    print(\"‚ùå IMAGE NOT FOUND!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nLooking for: {my_image}\")\n",
        "    print(f\"In directory: {os.getcwd()}\")\n",
        "    print(\"\\nüìù Instructions:\")\n",
        "    print(\"  1. Place your handwritten digit image in this folder\")\n",
        "    print(\"  2. Update 'my_image' variable above with your filename\")\n",
        "    print(\"  3. Run this cell again\")\n",
        "    print(\"\\nüí° Tip: You can drag & drop your image into the file browser\")\n",
        "    print(\"=\" * 70)\n",
        "else:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"üîç ANALYZING YOUR HANDWRITTEN DIGIT...\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Make prediction\n",
        "    predicted_digit, confidence, probabilities, orig_img, proc_img = predict_digit(\n",
        "        my_image,\n",
        "        trained_parameters,\n",
        "        invert=invert\n",
        "    )\n",
        "\n",
        "    # Display result\n",
        "    print(\"\\n\" + \"üéâ \" * 25)\n",
        "    print(f\"\\nThe uploaded handwritten digit is recognized as: {predicted_digit}\")\n",
        "    print(\"\\n\" + \"üéâ \" * 25)\n",
        "    print(f\"\\nConfidence Level: {confidence*100:.2f}%\")\n",
        "\n",
        "    # Show top 3 predictions\n",
        "    print(\"\\nüìä Top 3 Most Likely Digits:\")\n",
        "    top_3_indices = np.argsort(probabilities)[-3:][::-1]\n",
        "    for rank, idx in enumerate(top_3_indices, 1):\n",
        "        bar = \"‚ñà\" * int(probabilities[idx] * 40)\n",
        "        print(f\"  {rank}. Digit {idx}: {probabilities[idx]*100:5.2f}% {bar}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    # Original image\n",
        "    axes[0].imshow(orig_img, cmap='gray')\n",
        "    axes[0].set_title('üì∑ Your Original Image', fontsize=12, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Processed image\n",
        "    axes[1].imshow(proc_img, cmap='gray')\n",
        "    axes[1].set_title('üîß Processed (28√ó28)', fontsize=12, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Probability distribution\n",
        "    digits = np.arange(10)\n",
        "    colors = ['red' if i == predicted_digit else 'lightblue' for i in digits]\n",
        "    axes[2].bar(digits, probabilities, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
        "    axes[2].set_xlabel('Digit', fontsize=11, fontweight='bold')\n",
        "    axes[2].set_ylabel('Probability', fontsize=11, fontweight='bold')\n",
        "    axes[2].set_title(f'üìä Prediction: {predicted_digit}', fontsize=12, fontweight='bold', color='red')\n",
        "    axes[2].set_xticks(digits)\n",
        "    axes[2].set_ylim([0, 1])\n",
        "    axes[2].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n‚úÖ Prediction complete! Upload another image and run this cell again to test more.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bd32e53",
      "metadata": {
        "id": "8bd32e53"
      },
      "source": [
        "### üí° Quick Alternative: One-Line Prediction\n",
        "\n",
        "If you want to quickly test different images, use this simple command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9287557d",
      "metadata": {
        "id": "9287557d"
      },
      "outputs": [],
      "source": [
        "# Quick one-line prediction: Just change the filename and run!\n",
        "# For BLACK digit on WHITE background:\n",
        "display_prediction(\"my_digit.png\", trained_parameters, invert=True)\n",
        "\n",
        "# For WHITE digit on BLACK background (like MNIST):\n",
        "# display_prediction(\"my_digit.png\", trained_parameters, invert=False)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}